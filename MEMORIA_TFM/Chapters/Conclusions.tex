\chapter{Conclusions}
	\section{Conclusions}
		In this project, a tool has been developed to create visuals in Touch Designer, based on \ac{LLM} models, using information provided based on colors and shapes.
		
		In order to achieve \textbf{O\textsubscript{1} (Research and Training)}, as outlined in section \ref{item: O1}, several carefully evaluated approaches were explored. Various language models capable of text generation and natural language understanding were considered, with particular emphasis on ensuring compatibility with Touch Designer. The initial approach involved manually creating indexes and embeddings. This process consisted of generating vectors and weights, training the model with the processed data, and subsequently attempting to integrate the trained model into Touch Designer. However, due to the complexity and limitations of this method, an alternative solution was sought. Ultimately, the project adopted \ac{LOPS}, which provides native operators designed to integrate \ac{LLM} models directly into Touch Designer. These operators enable the creation of agent-based virtual assistants that can learn from user-provided documents and retain contextual memory. By leveraging this framework, the system can be trained using files containing information on specific topics and can subsequently generate visuals that are informed by and aligned with the embedded knowledge. This approach significantly streamlined the research and training process while ensuring effective integration within the Touch Designer environment.
		
		To achieve \textbf{O\textsubscript{2} (Tool Creation)}, previously defined alongside the first objective in section \ref{item: O2}, a workflow was developed within Touch Designer to enable the automatic generation of \ac{GLSL} shaders through a single user action. This tool processes structured information and allows an \ac{LLM}-based model to learn from it, generating varied visual outputs in response to user-defined inputs. Although a complete workflow has been successfully implemented, the system remains at an early stage of development and presents recurring limitations that have not yet been fully resolved. Several Touch Designer bases were created, each corresponding to a specific visual style. However, the intended scope of the tool extends beyond static visuals, with future development aimed at incorporating musical interaction and refining existing functionalities. It is also important to note that the current implementation was developed and tested using a relatively small dataset. When applied by an artist with extensive research material and a well-defined visual identity, and when populated with a larger and more diverse collection of documents, the tool has the potential to produce significantly more complex and sophisticated results.
		
	\section{Future lines}
		This project is considered to have significant potential for future development. \ac{LOPS} is a powerful tool offering a wide range of possibilities that have not yet been fully explored. Due to its recent emergence, there is currently very little documentation or reference material available. Consequently, a substantial portion of the project was devoted to understanding how the tool functions and resolving technical issues, which restricted the scope for development within the available timeframe.
		
		Despite these challenges, the project is conceived as an ongoing effort rather than a closed outcome tied solely to the submission of this work. Several issues remain unresolved, such as the error shown in Figure \ref{fig: ErrorApi}. For reasons that are not yet fully understood, the online model used, Gemini, occasionally fails. When this occurs, all connected agents encounter errors simultaneously. Additionally, shaders are sometimes not generated successfully, often due to incomplete, ambiguous or poorly structured prompts.
		Consequently, one of the main areas of focus for future work is to further reinforce and stabilise the workflow, as well as gain a deeper understanding of \ac{LOPS}â€™ capabilities and limitations. Continued experimentation and refinement are essential to improving reliability, enhancing automation and fully exploiting the system's creative potential.
		
		\begin{figure} [H]
			\centering
			\includegraphics[width=0.7\linewidth]{gfx/ErrorApi.png}
			\caption{Unknown error ralated with the API of Gemini }
			\label{fig: ErrorApi}
		\end{figure}
		
		On the other hand, improvements have been made to the system. One of our next goals is to add music to the project. We also want users to be able to upload their own songs, which the system will then use to create audio-reactive visuals and analyse the songs to determine the most suitable visuals for each one. Additionally, we are working on implementing stream diffusion to make the visuals much richer and more varied. Currently, the shaders that can be created are quite basic, but this new implementation could elevate this tool. This is a long-term project that will offer many more options if we continue working on it.
	